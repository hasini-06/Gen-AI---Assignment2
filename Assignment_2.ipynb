{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMCGF1iCuG+W11o1/FdmuhY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hasini-06/Gen-AI---Assignment2/blob/main/Assignment_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task - 1**"
      ],
      "metadata": {
        "id": "3IUuz6DDrAhu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install huggingface_hub"
      ],
      "metadata": {
        "id": "w_A3oEdLIurf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0c7612e-82f6-4360-b258-ce3941ab5302"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (0.33.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (1.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2025.7.14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import InferenceClient\n",
        "from getpass import getpass\n",
        "import textwrap\n",
        "\n",
        "HF_TOKEN = getpass(\"Enter the token : \")\n",
        "\n",
        "client=InferenceClient(model=\"deepset/roberta-base-squad2\",token=HF_TOKEN)\n",
        "\n",
        "question=input(\"Enter the query : \")\n",
        "\n",
        "context=\"The book was written by J.K. Rowling in 1997.\"\n",
        "\n",
        "try:\n",
        "  response=client.question_answering(context=context,question=question)\n",
        "  answer=response.get(\"answer\",\"answer not found\")\n",
        "  print(textwrap.fill(answer,width=50))\n",
        "\n",
        "except Exception as e:\n",
        "  print(\"Error please try again!!!\")\n",
        "  print(\"Details:\",e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXsfQBXSAHuo",
        "outputId": "a7a6059d-f941-4b4c-e43c-3c9a8df68a55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the token : ··········\n",
            "Enter the query : Who wrote the book\n",
            "J.K. Rowling\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "from transformers import pipeline\n",
        "from huggingface_hub import InferenceClient\n",
        "import traceback\n",
        "from getpass import getpass\n",
        "\n",
        "#Step-1:  Try loading GPT-2 locally\n",
        "\n",
        "try:\n",
        "  local_generator=pipeline(\"text-generation\",model=\"gpt2\")\n",
        "except Exception as e:\n",
        "  print(\"Failed to load GPT-2 locally:\",e)\n",
        "  local_generator=None\n",
        "\n",
        "#Step - 2: Set up Hugging Face API Client\n",
        "HF_API_TOKEN = getpass(\"Enter the token : \")\n",
        "client=InferenceClient(\n",
        "    model=\"mistralai/Mistral-7B-Instruct-v0.2\",\n",
        "    token=HF_API_TOKEN\n",
        ")\n",
        "\n",
        "#Step - 3: Fallback logic\n",
        "def generate_text(prompt):\n",
        "  try:\n",
        "    print(\"Trying GPT-2 locally....\")\n",
        "    if local_generator:\n",
        "      result=local_generator(prompt,max_length=50)[0][\"generated_text\"]\n",
        "      return f\"GPT-2 (local):\\n{result}\"\n",
        "    else:\n",
        "      raise RuntimeError(\"GPT-2 not available\")\n",
        "  except Exception as e:\n",
        "    print(\"Local GPT-2 failed. Failing back to Hugging face Inference API...\")\n",
        "    try:\n",
        "      messages = [\n",
        "          {\"role\": \"system\", \"content\":\"You are a helpful assistant.\"},\n",
        "          {\"role\": \"user\",\"content\": prompt}\n",
        "      ]\n",
        "      response = client.chat_completion(messages=messages, max_tokens = 50)\n",
        "      result = response.choices[0].message.content.strip()\n",
        "      return f\"Hugging Face API: \\n{result}\"\n",
        "    except Exception as api_error:\n",
        "      return f\"Both methods failed. \\nError:\\n{traceback.format_exc()}\"   #returns error in string format\n",
        "\n",
        "#Step-4 : prompt input and run\n",
        "user_input = input(\"Enter your prompt: \")\n",
        "output = generate_text(user_input)\n",
        "print(\"\\n\" + output)\n",
        "\n"
      ],
      "metadata": {
        "id": "79KK1Dl1CBsS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "719197fd-14e3-4f1d-f43e-bbc79884471a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.7.14)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter the token : ··········\n",
            "Enter your prompt: What are the uses of cycling\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Both `max_new_tokens` (=256) and `max_length`(=50) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trying GPT-2 locally....\n",
            "\n",
            "GPT-2 (local):\n",
            "What are the uses of cycling?\n",
            "\n",
            "It has been estimated that cycling in Australia contributes about $5 billion to the economy annually, a number that is expected to grow. A recent estimate by the Australian Institute of Sport suggests that cycling contributes to about $1 billion in economic activity.\n",
            "\n",
            "However, in 2011 the Australian Institute of Sport (AIS) published a report that found that cycling is one of the most important activities for human wellbeing and wellbeing.\n",
            "\n",
            "The AIS report found that cycling accounted for a significant proportion of the Australian economy in 2011-12.\n",
            "\n",
            "How did cycling impact Australia?\n",
            "\n",
            "Carrying a bike in Australia was not as often as people think. However, people may not have realised that cycling is one of the most important activities for their wellbeing.\n",
            "\n",
            "While cycling is a very popular activity in Australia, its impact on society is limited.\n",
            "\n",
            "There is no evidence that cycling causes serious social or economic damage to the environment.\n",
            "\n",
            "The AIS report found:\n",
            "\n",
            "There was a substantial increase in the number of Australians who rode their bikes at least once a week in the first year after the Government introduced the Cycling Policy.\n",
            "\n",
            "The increased activity contributed to a rise in the number of people cycling in Australia.\n",
            "\n",
            "Carrying a\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task - 2**"
      ],
      "metadata": {
        "id": "dMF-knbxzw1Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "4VBr6aF5z2qM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0474e4d7-ac67-4f2b-f1ad-8a0bb3820dab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.7.14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "import textwrap\n",
        "\n",
        "\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")   #GPT-2 Tokenzier\n",
        "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")   #GPT-2 Model\n",
        "\n",
        "\n",
        "pad_token_id = tokenizer.eos_token_id   #Pad token to avoids warnings\n",
        "model.config.pad_token_id = pad_token_id    #Updates the model config to use the eos_token as the pad token.\n",
        "\n",
        "\n",
        "def generate_story(prompt, temperature=0.7):\n",
        "    \"\"\"\n",
        "    Generates a story based on a given prompt and temperature.\n",
        "\n",
        "    Args:\n",
        "        prompt (str): The input text to continue.\n",
        "        temperature (float): Controls randomness of output (higher = more random).\n",
        "\n",
        "    Returns:\n",
        "        str: Generated story text.\n",
        "    \"\"\"\n",
        "    try:\n",
        "\n",
        "        input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")   #Changes iput to ID's\n",
        "        output_ids = model.generate(\n",
        "            input_ids,\n",
        "            max_length=150,\n",
        "            do_sample=True,\n",
        "            top_k=50,   #Considers only the top 50 most likely next tokens.\n",
        "            top_p=0.95,   #chooses tokens from top 95% of cumulative probability.\n",
        "            temperature=temperature,\n",
        "            repetition_penalty=1.2,   #Penalizes repeating the same phrases to make text more diverse\n",
        "            pad_token_id=pad_token_id  # avoid padding warning\n",
        "        )\n",
        "\n",
        "        story = tokenizer.decode(output_ids[0], skip_special_tokens=True)   # Decode and return the story\n",
        "        return story\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"Error generating story:\", e)   #Error-handling\n",
        "        return None\n",
        "\n",
        "\n",
        "prompt=\"Once upon a time there lived a dragon\"\n",
        "temperature=[0.5,0.7,0.9,1.3]\n",
        "\n",
        "for i in temperature:\n",
        "  story=generate_story(prompt,i)    #function calling\n",
        "  print(\"temperature : \"+str(i))\n",
        "  print(textwrap.fill(story,width=80))\n",
        "  print(\"\\n\")\n"
      ],
      "metadata": {
        "id": "lMV93EhDEHX6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "674a6c15-ae2d-4ba4-86ae-1c52f90a3dcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "temperature : 0.5\n",
            "Once upon a time there lived a dragon who was not of the same race as you. \"You\n",
            "are my friend, I trust your judgment.\" The Dragon said in his voice and then\n",
            "turned to face me again with that smile on her lips she still had it now but\n",
            "this one didn't look like anything else than something very familiar even though\n",
            "he knew what kind they were at least for him because if nothing more could be\n",
            "done about them all would just vanish into thin air… \"I'm sorry…\" She whispered\n",
            "coldly before turning back around once we'd left our room together after talking\n",
            "some good old fashioned game play while looking up from their bookshelf trying\n",
            "desperately hard against any urge or emotion which might have been causing such\n",
            "confusion amongst us so\n",
            "\n",
            "\n",
            "temperature : 0.7\n",
            "Once upon a time there lived a dragon, who was known as the Dragon King of\n",
            "Rohan. The man's name is Valar and he held an immense fortune in this\n",
            "world...but it wasn't enough to get him into Imperial hands; she also had his\n",
            "blood on her hand! In order for that ancient vampire warrior queen named Vaira\n",
            "(Ranma) not only would they have needed someone else from their past lives but\n",
            "I'd like you to know something about what happened next!\" \"I've been wondering\n",
            "whether or how we could help my brother so easily.\" She told me with no doubt at\n",
            "all - even if one thought back further than three decades ago when Velen saw\n",
            "both herself and Renesne together? This made\n",
            "\n",
            "\n",
            "temperature : 0.9\n",
            "Once upon a time there lived a dragonborn, and one whose name was Zethron. And\n",
            "the dragons that survived his life were only just too powerful to resist him\n",
            "with their own bloodline; at least until they turned against it again for its\n",
            "evil traits.[3a] \"You know how I'm going.\" ―Rorik Dornan [src][4e-17b/dramatic\n",
            "translation]] \"And now you're all dead! Or rather not alive anymore...!\" ―Zivra\n",
            "Stalhrim in battle after she destroyed Yvardenfell on Serana Island[citation\n",
            "needed]) While Ondar's death may have been inevitable considering he'd faced an\n",
            "army of monstrous beings known as Demons\n",
            "\n",
            "\n",
            "temperature : 1.3\n",
            "Once upon a time there lived a dragon, I went in at last. Now the land will\n",
            "end.\" So my journey through this ancient hellland is filled with dragons; but\n",
            "when we reach some place far away like Sullustis - if you call them that? It was\n",
            "not for any purpose of mine to enter these cursed cities! Then how about your\n",
            "life?!  ...\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}